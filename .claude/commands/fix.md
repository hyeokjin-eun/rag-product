# Fix 커맨드

버그를 수정합니다.

## 입력

- $ARGUMENTS: 도메인 이름 (예: documents, search, embeddings, rag)

## 작업 흐름

```
[1. 버그 정보 수집]
        ↓
[2. 관련 코드 파악]
        ↓
[3. 영향 범위 분석]
        ↓
[4. 수정 작업]
        ↓
[5. 빌드 및 검증]
        ↓
[6. 테스트 확인]
        ↓
[7. 완료]
```

---

## 작업 순서

### 1. 버그 정보 수집

사용자에게 다음을 질문하세요:

- 어떤 버그인가요? (증상 설명)
- 재현 방법이 있나요?
- 예상 동작 vs 실제 동작은?
- 에러 메시지가 있나요?

### 2. 관련 코드 파악

다음 파일들을 확인하세요:

```
app/domains/$ARGUMENTS/
├── schemas.py
├── service.py
└── repository.py

app/api/v1/$ARGUMENTS.py

tests/
├── unit/domains/test_$ARGUMENTS.py
└── integration/test_$ARGUMENTS_api.py
```

### 3. 영향 범위 분석

버그 수정이 영향을 미칠 수 있는 부분을 파악하세요:

| 확인 항목 | 내용 |
|-----------|------|
| 직접 영향 | 수정할 함수/메서드 |
| 호출자 | 이 함수를 호출하는 코드 |
| 의존성 | 다른 도메인에 영향? |
| 테스트 | 관련 테스트 케이스 |

사용자에게 영향 범위를 보여주고 확인받으세요.

### 4. 수정 작업

버그를 수정하세요:

1. 원인이 되는 코드 수정
2. 필요시 관련 코드도 수정
3. 수정 내용을 사용자에게 설명

### 5. 빌드 및 검증

수정 후 다음을 실행하여 검증:

```bash
# 1. 타입 체크
mypy app/domains/$ARGUMENTS/

# 2. 린트 검사
ruff check app/domains/$ARGUMENTS/

# 3. 수정된 파일 관련 테스트
pytest tests/ -k "$ARGUMENTS" -v
```

**검증 실패 시:**
- 에러 메시지 확인 후 코드 재수정
- 모든 검증 통과할 때까지 반복

### 6. 테스트 확인

| 확인 항목 | 내용 |
|-----------|------|
| 기존 테스트 | 기존 테스트가 통과하는지 확인 |
| 버그 재현 테스트 | 버그를 재현하는 테스트 추가 (권장) |
| 회귀 테스트 | 다른 기능이 깨지지 않았는지 확인 |

### 7. 완료 보고

```
✅ 버그 수정 완료

## 수정 내용
- {수정한 파일}: {수정 내용}

## 원인
- {버그 원인 설명}

## 영향 범위
- {영향받는 기능}

## 테스트
- [ ] 기존 테스트 통과
- [ ] 버그 재현 테스트 추가

## 커밋
fix: {버그 설명}
```

---

## 스펙 문서 수정이 필요한 경우

버그가 스펙과 구현의 불일치로 인한 것이라면:

1. 스펙이 잘못된 경우 → 스펙 수정
2. 구현이 잘못된 경우 → 코드 수정 (이 커맨드)
3. 둘 다 수정 필요 → 스펙 수정 후 코드 수정

스펙 수정이 필요하면 사용자에게 알리고 `.claude/specs/$ARGUMENTS.md` 해당 섹션을 수정하세요.
